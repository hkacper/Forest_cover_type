{"cells":[{"cell_type":"code","source":"#install.packages('PerformanceAnalytics')\n#install.packages('caret')\n#install.packages('e1071')\n#install.packages('mlbench')\n#install.packages('randomForest')\nlibrary(PerformanceAnalytics)\nlibrary(caret)\nlibrary(randomForest)\nlibrary(e1071)\nlibrary(pROC)\n\n# normalize features to (0:1)\nnormalize <- function (x) {\n  return ((x - min(x)) / (max(x) - min(x)))\n}\n\ndata = read.csv(file=\"../input/forest-cover-type-prediction/train.csv\", header=TRUE, sep=',')\n\ndim(data)\nstr(data)\nsummary(data)\ntable(is.na(data))\nklasy <- aggregate(data$Cover_Type, by=list(data$Cover_Type), FUN=length)\n\n# drop unnecesarry columns\ndata <- subset(data, select = -c(Id, Soil_Type7, Soil_Type15))\ndata$Cover_Type <- as.factor(data$Cover_Type)\n\n# check and delete highly correlated features\ncorrelationMatrix <- cor(data[,1:10])\nprint(correlationMatrix)\nhighlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.75, verbose=TRUE)\nprint(highlyCorrelated)\n\ndata <- subset(data, select = -c(Hillshade_3pm))\n\n# normalize columns 1:10\ni=1\nfor (i in 1:10) {\n  data[,i] <- normalize(data[,i])\n}\n\n\n# split to train and test\nsmp_size <- floor(0.8 * nrow(data))\nset.seed(123)\ntrain_ind <- sample(seq_len(nrow(data)), size = smp_size)\n\ndata_train <- data[train_ind, ]\ndata_test <- data[-train_ind, ]\n\n######################################## RANDOM FOREST\n\n# finding best 'mtry' parameter\n# a=c()\n# for (i in 1:25) {\n#  rfmodel <- randomForest(Cover_Type ~., data=data_train, ntree=500, importance=TRUE, mtry=i)\n#  predValid <- predict(rfmodel, data_test, type=\"class\")\n#  a[i] <- mean(predValid == data_test$Cover_Type)\n#  message(\"i = \", i, \", a = \", a[i])\n# }\n# a\n# plot(1:25, a, xlab=\"Liczba losowanych atrybutĂłw\", ylab=\"SkutecznoĹ›Ä‡ predykcji\", main=\"SkutecznoĹ›Ä‡ modelu w zaleznoĹ›ci od liczby losowanych atrybutĂłw\")\n\n\n# RF model\nrandom_forest <- randomForest(Cover_Type ~., data=data_train, ntree=500, importance=TRUE, mtry=20)\n\n# check on test dataset\nrf_prediction <- predict(random_forest, data_test, type=\"class\")\nconfusionMatrix(rf_prediction, data_test$Cover_Type)\n# feature importance\nimportance_1 <- importance(random_forest, type=1)\nimportance_2 <- importance(random_forest, type=2)\nvarImpPlot(random_forest, n.var=20, type=1)\nvarImpPlot(random_forest, n.var=20, type=2)\n\nrf_roc <- multiclass.roc(data_test$Cover_Type, factor(rf_prediction, ordered=TRUE))\nprint(rf_roc)\n\n\n# ROC for every class (one vs others)\nrf_prediction_prob <- as.data.frame(predict(random_forest, data_test, type=\"prob\"))\nrf_prediction_prob$predict <-names(rf_prediction_prob)[1:7][apply(rf_prediction_prob[,1:7], 1, which.max)]\nrf_prediction_prob$observed <- data_test$Cover_Type\ncolnames(rf_prediction_prob)[which(names(rf_prediction_prob)==1)]<-\"a\"\ncolnames(rf_prediction_prob)[which(names(rf_prediction_prob)==2)]<-\"b\"\ncolnames(rf_prediction_prob)[which(names(rf_prediction_prob)==3)]<-\"c\"\ncolnames(rf_prediction_prob)[which(names(rf_prediction_prob)==4)]<-\"d\"\ncolnames(rf_prediction_prob)[which(names(rf_prediction_prob)==5)]<-\"e\"\ncolnames(rf_prediction_prob)[which(names(rf_prediction_prob)==6)]<-\"f\"\ncolnames(rf_prediction_prob)[which(names(rf_prediction_prob)==7)]<-\"g\"\nroc1 <- roc(ifelse(rf_prediction_prob$observed==1, \"1\", \"rest\"), as.numeric(rf_prediction_prob$a))\nroc2 <- roc(ifelse(rf_prediction_prob$observed==2, \"2\", \"rest\"), as.numeric(rf_prediction_prob$b))\nroc3 <- roc(ifelse(rf_prediction_prob$observed==3, \"3\", \"rest\"), as.numeric(rf_prediction_prob$c))\nroc4 <- roc(ifelse(rf_prediction_prob$observed==4, \"4\", \"rest\"), as.numeric(rf_prediction_prob$d))\nroc5 <- roc(ifelse(rf_prediction_prob$observed==5, \"5\", \"rest\"), as.numeric(rf_prediction_prob$e))\nroc6 <- roc(ifelse(rf_prediction_prob$observed==6, \"6\", \"rest\"), as.numeric(rf_prediction_prob$f))\nroc7 <- roc(ifelse(rf_prediction_prob$observed==7, \"7\", \"rest\"), as.numeric(rf_prediction_prob$g))\nplot(roc1, ylab=\"True Positive Rate\", xlab=\"False Positive Rate\", main=\"Krzywe ROC lasu losowego\")\nlines(roc2, col=\"blue\")\nlines(roc3, col=\"red\")\nlines(roc4, col=\"darkgreen\")\nlines(roc5, col=\"orange\")\nlines(roc6, col=\"darkmagenta\")\nlines(roc7, col=\"cyan\")\nlegend(\"bottomright\", legend=c(1, 2, 3, 4, 5, 6, 7), col=c(\"black\", \"blue\", \"red\", \"darkgreen\", \"orange\", \"darkmagenta\", \"cyan\"), lty=1)\n\n######################################## SVM\n# drop 1 hot encoded features\ndane_bez_1hot <- data[-c(10:51)]\n# split new dataset\ndane_bez_1hot_train <- dane_bez_1hot[train_ind, ]\ndane_bez_1hot_test <- dane_bez_1hot[-train_ind, ]\n\n# tune SVM\n#tuned_svm_parameters <- tune.svm(Cover_Type ~., data=dane_bez_1hot_train, gamma=10^(-5:-1), cost=10^(-3:1))\n\n# save best model to a file\n#saveRDS(tuned_svm_parameters$best.model, './best_svm_model.rds')\n\n# read model from a file\nbest_svm_model <- readRDS('../input/forest-cover-type-prediction/best_svm_model.rds')\n# same as in RF\nsvm_prediction <- predict(best_svm_model, data_test, type=\"class\")\nconfusionMatrix(svm_prediction, data_test$Cover_Type)\n \nsvm_roc <- multiclass.roc(data_test$Cover_Type, factor(svm_prediction, ordered=TRUE))\nprint(svm_roc)\n\n\n######################################## NAIVE BAYES\n# same as before\nnaive_bayes <- naiveBayes(Cover_Type ~., data=dane_bez_1hot_train)\nnb_prediction <- predict(naive_bayes, dane_bez_1hot_test, type=\"class\")\nconfusionMatrix(nb_prediction, dane_bez_1hot_test$Cover_Type)\nnb_roc <- multiclass.roc(data_test$Cover_Type, factor(nb_prediction, ordered=TRUE))\nprint(nb_roc)\n\n\ntest = read.csv(file=\"../input/forest-cover-type-prediction/test.csv\", header=TRUE, sep=',')\ntest$Cover_Type<-predict(random_forest,test)\noutput<-data.frame(test$Id,test$Cover_Type)\ncolnames(output) <- c(\"Id\", \"Cover_Type\")\nwrite.csv(output,file=\"submission.csv\",row.names=FALSE)","metadata":{"collapsed":false,"_kg_hide-input":false},"execution_count":0,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}